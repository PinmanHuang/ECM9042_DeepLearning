{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "**problem**: Chapter 6 of the textbook.\n",
    "\n",
    "In this exercise, you will construct a convolutional neural network (CNN) for image recognition using the MNIST dataset. This dataset is a subset of a larger set available from NIST. The MNIST dataset contains a total of 70,000 images of handwritten digits from 0 to 9 with corresponding labels, of which 55,000 examples are in the training set, 5,000 in the validation set, and 10,000 in the test set. The digits have been size-normalized and centered in a fixedsize image, so you donâ€™t need to do any preprocessing to the images.\n",
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d134c2e278>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d1314f3f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 1\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "\n",
    "    def __init__(self, learning_rate=0.5, debug=False):\n",
    "        \"\"\"\n",
    "        Train NeuralNetwork by fixed learning rate\n",
    "        \"\"\"\n",
    "        self.neuron_layers = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.debug = debug\n",
    "\n",
    "    def train(self, dataset):\n",
    "        for inputs, outputs in dataset:\n",
    "            self.feed_forward(inputs)\n",
    "            self.feed_backword(outputs)\n",
    "            self.update_weights(self.learning_rate)\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        s = inputs\n",
    "        for (i, l) in enumerate(self.neuron_layers):\n",
    "            s = l.feed_forward(s)\n",
    "            if self.debug:\n",
    "                print (\"Layer %s:\" % (i+1), \" output:%s\" % s)\n",
    "        return s\n",
    "\n",
    "    def feed_backword(self, outputs):\n",
    "        layer_num = len(self.neuron_layers)\n",
    "        l = layer_num\n",
    "        previous_deltas = [] \n",
    "        while l != 0:\n",
    "            current_layer = self.neuron_layers[l - 1]\n",
    "            if len(previous_deltas) == 0:\n",
    "                for i in range(len(current_layer.neurons)):\n",
    "                    error = -(outputs[i] - current_layer.neurons[i].output)\n",
    "                    current_layer.neurons[i].calculate_delta(error)\n",
    "            else:\n",
    "                previous_layer = self.neuron_layers[l]\n",
    "                for i in range(len(current_layer.neurons)):\n",
    "                    error = 0\n",
    "                    for j in range(len(previous_deltas)):\n",
    "                        error += previous_deltas[j] * previous_layer.neurons[j].weights[i]\n",
    "                    current_layer.neurons[i].calculate_delta(error)\n",
    "            previous_deltas = current_layer.get_deltas()\n",
    "            if self.debug:\n",
    "                print (\"Layer %s:\" % l, \"deltas:%s\" % previous_deltas)\n",
    "            l -= 1\n",
    "\n",
    "    def update_weights(self, learning_rate):\n",
    "        for l in self.neuron_layers:\n",
    "            l.update_weights(learning_rate)\n",
    "\n",
    "    def calculate_total_error(self, dataset):\n",
    "        \"\"\"\n",
    "        Return mean squared error of dataset\n",
    "        \"\"\"\n",
    "        total_error = 0\n",
    "        for inputs, outputs in dataset:\n",
    "            actual_outputs = self.feed_forward(inputs)\n",
    "            for i in range(len(outputs)):\n",
    "                total_error += (outputs[i] - actual_outputs[i]) ** 2\n",
    "        return total_error\n",
    "\n",
    "    def get_output(self, inputs):\n",
    "        return self.feed_forward(inputs)\n",
    "\n",
    "    def add_layer(self, neruon_layer):\n",
    "        self.neuron_layers.append(neruon_layer)\n",
    "\n",
    "    def dump(self):\n",
    "        for (i, l) in enumerate(self.neuron_layers):\n",
    "            print (\"Dump layer: %s\" % (i+1))\n",
    "            l.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronLayer(object):\n",
    "\n",
    "    def __init__(self, input_num, neuron_num, init_weights=[], bias=1):\n",
    "        self.neurons = []\n",
    "        weight_index = 0\n",
    "        for i in range(neuron_num):\n",
    "            n = Neuron(input_num)\n",
    "            for j in range(input_num):\n",
    "                if weight_index < len(init_weights):\n",
    "                    n.weights[j] = init_weights[weight_index]\n",
    "                    weight_index += 1\n",
    "            n.bias = bias\n",
    "            self.neurons.append(n)\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        outputs = []\n",
    "        for n in self.neurons:\n",
    "            outputs.append(n.calculate_output(inputs))\n",
    "        return outputs\n",
    "\n",
    "    def get_deltas(self):\n",
    "        return [n.delta for n in self.neurons]\n",
    "\n",
    "    def update_weights(self, learning_rate):\n",
    "        for n in self.neurons:\n",
    "            n.update_weights(learning_rate)\n",
    "\n",
    "    def dump(self):\n",
    "        for (i, n) in enumerate(self.neurons):\n",
    "            print (\"\\t-Dump neuron: %s\" % (i+1))\n",
    "            n.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron ##\n",
    "### Initialize the Weights of Neural Network ###\n",
    "Using random function to randomly generate the weights.\n",
    "### Calculate Output ###\n",
    "$$z=\\omega_{1}*x_{1}+\\omega_{2}âˆ—x_{2}+\\omega_{3}âˆ—bias$$\n",
    "\n",
    "then using activation function(sigmoid function) to calculate the output\n",
    "\n",
    "$$s=\\frac{1}{1+e^{âˆ’z}}$$\n",
    "### Activation Function ###\n",
    "$$s=\\frac{1}{1+e^{âˆ’z}}$$\n",
    "### Calculate Delta ###\n",
    "The error influence:\n",
    "$$\\delta_{L}=(realOutputâˆ’expectOutput)âˆ—gâ€²(z)$$\n",
    "\n",
    "$$g'(z)=oâˆ—(1âˆ’o)$$\n",
    "### Update Weights ###\n",
    "$$\\delta_{L}=\\omega_{L+1}\\delta_{L+1}âˆ—gâ€²(z)$$\n",
    "\n",
    "new weights: $$\\omega_{i}=\\omega_{i}âˆ’\\alphaâˆ—\\deltaâˆ—x_{i}$$\n",
    "\n",
    "new bias: $$\\omega_{bias}=\\omega_{bias}âˆ’\\alphaâˆ—\\delta$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(object):\n",
    "\n",
    "    def __init__(self, weight_num):\n",
    "        self.weights = []\n",
    "        self.bias = 0\n",
    "        self.output = 0\n",
    "        self.delta = 0\n",
    "        self.inputs = []\n",
    "        for i in range(weight_num):\n",
    "            self.weights.append(random.random())\n",
    "\n",
    "    def calculate_output(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        if len(inputs) != len(self.weights):\n",
    "            raise Exception(\"Input number not fit weight number\")\n",
    "        self.output = 0\n",
    "        for (i, w) in enumerate(self.weights):\n",
    "            self.output += w * inputs[i]\n",
    "        self.output = self.activation_function(self.output + self.bias)\n",
    "        return self.output\n",
    "\n",
    "    def activation_function(self, x):\n",
    "        \"\"\"Using sigmoid function\"\"\"\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    def calculate_delta(self, error):\n",
    "        \"\"\" Using g' of sigmoid \"\"\"\n",
    "        self.delta = error * self.output * (1 - self.output)\n",
    "\n",
    "    def update_weights(self, learning_rate):\n",
    "        for (i, w) in enumerate(self.weights):\n",
    "            new_w = w - learning_rate * self.delta * self.inputs[i]\n",
    "            self.weights[i] = new_w\n",
    "        self.bias = self.bias - learning_rate * self.delta\n",
    "\n",
    "    def dump(self):\n",
    "        print (\"\\t\\t-- weights:\", self.weights)\n",
    "        print (\"\\t\\t-- bias:\", self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "hidden_layer_1 = NeuronLayer(input_num=15, neuron_num=10, bias=1)\n",
    "hidden_layer_2 = NeuronLayer(input_num=10, neuron_num=10, bias=1)\n",
    "output_layer = NeuronLayer(input_num=10, neuron_num=1, bias=1)\n",
    "nn.add_layer(hidden_layer_1)\n",
    "nn.add_layer(hidden_layer_2)\n",
    "nn.add_layer(output_layer)\n",
    "# nn.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking = []\n",
    "for i in range(1000):\n",
    "    nn.train(dataset)\n",
    "    tracking.append(nn.calculate_total_error(dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
