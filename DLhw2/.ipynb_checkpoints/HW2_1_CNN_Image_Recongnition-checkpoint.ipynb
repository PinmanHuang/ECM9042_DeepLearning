{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "**problem**: Chapter 6 of the textbook.\n",
    "\n",
    "In this exercise, you will construct a convolutional neural network (CNN) for image recognition using the MNIST dataset. This dataset is a subset of a larger set available from NIST. The MNIST dataset contains a total of 70,000 images of handwritten digits from 0 to 9 with corresponding labels, of which 55,000 examples are in the training set, 5,000 in the validation set, and 10,000 in the test set. The digits have been size-normalized and centered in a fixedsize image, so you don’t need to do any preprocessing to the images.\n",
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "\n",
    "    def __init__(self, learning_rate=0.5, debug=False):\n",
    "        \"\"\"\n",
    "        Train NeuralNetwork by fixed learning rate\n",
    "        \"\"\"\n",
    "        self.neuron_layers = []\n",
    "        self.batch_error = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.debug = debug\n",
    "\n",
    "    def train(self, dataset, mini_batch):\n",
    "        if mini_batch:\n",
    "            batch_num = 0\n",
    "            self.batch_error = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "            for inputs, outputs in dataset:\n",
    "                if (batch_num%BATCH_SIZE == BATCH_SIZE-1) or (batch_num == len(dataset)):\n",
    "                    self.feed_forward(inputs)\n",
    "                    calculate_batch_error(outputs)\n",
    "                    self.batch_error = self.batch_error/(batch_num%BATCH_SIZE+1)\n",
    "                    feed_backword_batch(outputs)\n",
    "                    self.update_weights(self.learning_rate)\n",
    "                    self.batch_error = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                else:\n",
    "                    self.feed_forward(inputs)\n",
    "                    calculate_batch_error(outputs)\n",
    "                batch_num += 1\n",
    "        else:\n",
    "            for inputs, outputs in dataset:\n",
    "                \n",
    "                self.feed_forward(inputs)\n",
    "                self.feed_backword(outputs)\n",
    "                self.update_weights(self.learning_rate)\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        s = inputs\n",
    "        for (i, l) in enumerate(self.neuron_layers):\n",
    "            s = l.feed_forward(s)\n",
    "            if self.debug:\n",
    "                print (\"Layer %s:\" % (i+1), \" output:%s\" % s)\n",
    "        return s\n",
    "\n",
    "    def feed_backword(self, outputs):\n",
    "        layer_num = len(self.neuron_layers)\n",
    "        l = layer_num\n",
    "        previous_deltas = [] \n",
    "        while l != 0:\n",
    "            current_layer = self.neuron_layers[l - 1]\n",
    "            if len(previous_deltas) == 0:\n",
    "                for i in range(len(current_layer.neurons)):\n",
    "                    error = -(outputs[i] - current_layer.neurons[i].output)\n",
    "                    current_layer.neurons[i].calculate_delta(error)\n",
    "            else:\n",
    "                previous_layer = self.neuron_layers[l]\n",
    "                for i in range(len(current_layer.neurons)):\n",
    "                    error = 0\n",
    "                    for j in range(len(previous_deltas)):\n",
    "                        error += previous_deltas[j] * previous_layer.neurons[j].weights[i]\n",
    "                    current_layer.neurons[i].calculate_delta(error)\n",
    "            previous_deltas = current_layer.get_deltas()\n",
    "            if self.debug:\n",
    "                print (\"Layer %s:\" % l, \"deltas:%s\" % previous_deltas)\n",
    "            l -= 1\n",
    "            \n",
    "    def feed_backword_batch(self, outputs):\n",
    "        layer_num = len(self.neuron_layers)\n",
    "        l = layer_num\n",
    "        previous_deltas = [] \n",
    "        # Batch size - fitst output\n",
    "        current_layer = self.neuron_layers[l - 1]\n",
    "        for i in range(len(current_layer.neurons)):\n",
    "            error = self.batch_error\n",
    "            current_layer.neurons[i].calculate_delta(error)\n",
    "        previous_deltas = current_layer.get_deltas()\n",
    "        if self.debug:\n",
    "            print (\"Layer %s:\" % l, \"deltas:%s\" % previous_deltas)\n",
    "        l -= 1\n",
    "        # Batch size\n",
    "        while l != 0:\n",
    "            current_layer = self.neuron_layers[l - 1]\n",
    "            if len(previous_deltas) == 0:\n",
    "                for i in range(len(current_layer.neurons)):\n",
    "                    error = -(outputs[i] - current_layer.neurons[i].output)\n",
    "                    current_layer.neurons[i].calculate_delta(error)\n",
    "            else:\n",
    "                previous_layer = self.neuron_layers[l]\n",
    "                for i in range(len(current_layer.neurons)):\n",
    "                    error = 0\n",
    "                    for j in range(len(previous_deltas)):\n",
    "                        error += previous_deltas[j] * previous_layer.neurons[j].weights[i]\n",
    "                    current_layer.neurons[i].calculate_delta(error)\n",
    "            previous_deltas = current_layer.get_deltas()\n",
    "            if self.debug:\n",
    "                print (\"Layer %s:\" % l, \"deltas:%s\" % previous_deltas)\n",
    "            l -= 1\n",
    "\n",
    "    def update_weights(self, learning_rate):\n",
    "        for l in self.neuron_layers:\n",
    "            l.update_weights(learning_rate)\n",
    "\n",
    "    def calculate_total_error(self, dataset):\n",
    "        \"\"\"\n",
    "        Return mean squared error of dataset\n",
    "        \"\"\"\n",
    "        total_error = 0\n",
    "        for inputs, outputs in dataset:\n",
    "            actual_outputs = self.feed_forward(inputs)\n",
    "            for i in range(len(outputs)):\n",
    "                total_error += (outputs[i] - actual_outputs[i]) ** 2\n",
    "        return total_error\n",
    "\n",
    "    def calculate_batch_error(self, outputs):\n",
    "        layer_num = len(self.neuron_layers)\n",
    "        l = layer_num\n",
    "        current_layer = self.neuron_layers[l - 1]\n",
    "        for i in range(len(current_layer.neurons)):\n",
    "            self.batch_error[i] -= (outputs[i] - current_layer.neurons[i].output)\n",
    "\n",
    "    def get_output(self, inputs):\n",
    "        return self.feed_forward(inputs)\n",
    "\n",
    "    def add_layer(self, neruon_layer):\n",
    "        self.neuron_layers.append(neruon_layer)\n",
    "\n",
    "    def dump(self):\n",
    "        for (i, l) in enumerate(self.neuron_layers):\n",
    "            print (\"Dump layer: %s\" % (i+1))\n",
    "            l.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronLayer(object):\n",
    "\n",
    "    def __init__(self, input_num, neuron_num, init_weights=[], bias=1):\n",
    "        self.neurons = []\n",
    "        weight_index = 0\n",
    "        for i in range(neuron_num):\n",
    "            n = Neuron(input_num)\n",
    "            for j in range(input_num):\n",
    "                if weight_index < len(init_weights):\n",
    "                    n.weights[j] = init_weights[weight_index]\n",
    "                    weight_index += 1\n",
    "            n.bias = bias\n",
    "            self.neurons.append(n)\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        outputs = []\n",
    "        for n in self.neurons:\n",
    "            outputs.append(n.calculate_output(inputs))\n",
    "        return outputs\n",
    "\n",
    "    def get_deltas(self):\n",
    "        return [n.delta for n in self.neurons]\n",
    "\n",
    "    def update_weights(self, learning_rate):\n",
    "        for n in self.neurons:\n",
    "            n.update_weights(learning_rate)\n",
    "\n",
    "    def dump(self):\n",
    "        for (i, n) in enumerate(self.neurons):\n",
    "            print (\"\\t-Dump neuron: %s\" % (i+1))\n",
    "            n.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron ##\n",
    "### Initialize the Weights of Neural Network ###\n",
    "Using random function to randomly generate the weights.\n",
    "### Calculate Output ###\n",
    "$$z=\\omega_{1}*x_{1}+\\omega_{2}∗x_{2}+\\omega_{3}∗bias$$\n",
    "\n",
    "then using activation function(sigmoid function) to calculate the output\n",
    "\n",
    "$$s=\\frac{1}{1+e^{−z}}$$\n",
    "\n",
    "then using activation function(relu function) to calculate the output\n",
    "\n",
    "$$s=max(x, 0)$$\n",
    "### Activation Function ###\n",
    "$$s=\\frac{1}{1+e^{−z}}$$\n",
    "### Calculate Delta ###\n",
    "The error influence:\n",
    "$$\\delta_{L}=(realOutput−expectOutput)∗g′(z)$$\n",
    "\n",
    "$$g'(z)=o∗(1−o)$$\n",
    "### Update Weights ###\n",
    "$$\\delta_{L}=\\omega_{L+1}\\delta_{L+1}∗g′(z)$$\n",
    "\n",
    "new weights: $$\\omega_{i}=\\omega_{i}−\\alpha∗\\delta∗x_{i}$$\n",
    "\n",
    "new bias: $$\\omega_{bias}=\\omega_{bias}−\\alpha∗\\delta$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(object):\n",
    "\n",
    "    def __init__(self, weight_num):\n",
    "        self.weights = []\n",
    "        self.bias = 0\n",
    "        self.output = 0\n",
    "        self.delta = 0\n",
    "        self.inputs = []\n",
    "        for i in range(weight_num):\n",
    "            self.weights.append(random.random())\n",
    "\n",
    "    def calculate_output(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        if len(inputs) != len(self.weights):\n",
    "            raise Exception(\"Input number not fit weight number\")\n",
    "        self.output = 0\n",
    "        for (i, w) in enumerate(self.weights):\n",
    "            self.output += w * inputs[i]\n",
    "        self.output = self.activation_function(self.output + self.bias)\n",
    "        return self.output\n",
    "\n",
    "    def activation_function(self, x):\n",
    "        \"\"\"Using sigmoid function\"\"\"\n",
    "        #return 1 / (1 + math.exp(-x))\n",
    "        \"\"\"Using relu function\"\"\"\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def calculate_delta(self, error):\n",
    "        \"\"\" Using g' of sigmoid \"\"\"\n",
    "        self.delta = error * self.output * (1 - self.output)\n",
    "\n",
    "    def update_weights(self, learning_rate):\n",
    "        for (i, w) in enumerate(self.weights):\n",
    "            new_w = w - learning_rate * self.delta * self.inputs[i]\n",
    "            self.weights[i] = new_w\n",
    "        self.bias = self.bias - learning_rate * self.delta\n",
    "\n",
    "    def dump(self):\n",
    "        print (\"\\t\\t-- weights:\", self.weights)\n",
    "        print (\"\\t\\t-- bias:\", self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Convolution ##\n",
    "\n",
    "<img src=\"./forwardpass_convolution.PNG\">\n",
    "$$h_{11}=\\omega_{11}*x_{11}+\\omega_{12}∗x_{12}+\\omega_{21}∗x_{21}+\\omega_{22}∗x_{22}$$\n",
    "$$h_{12}=\\omega_{11}*x_{12}+\\omega_{12}∗x_{13}+\\omega_{21}∗x_{22}+\\omega_{22}∗x_{23}$$\n",
    "$$h_{21}=\\omega_{11}*x_{21}+\\omega_{12}∗x_{22}+\\omega_{21}∗x_{31}+\\omega_{22}∗x_{32}$$\n",
    "$$h_{22}=\\omega_{11}*x_{22}+\\omega_{12}∗x_{23}+\\omega_{21}∗x_{32}+\\omega_{22}∗x_{33}$$\n",
    "\n",
    "## Backward Convolution ##\n",
    "\n",
    "<img src=\"./backwardpass_convolution.PNG\">\n",
    "$$\\delta\\omega_{11}=x_{11}\\delta h_{11}+x_{12}\\delta h_{12}+x_{21}\\delta h_{21}+x_{22}\\delta h_{22}$$\n",
    "$$\\delta\\omega_{12}=x_{12}\\delta h_{11}+x_{13}\\delta h_{12}+x_{22}\\delta h_{21}+x_{23}\\delta h_{22}$$\n",
    "$$\\delta\\omega_{21}=x_{21}\\delta h_{11}+x_{22}\\delta h_{12}+x_{31}\\delta h_{21}+x_{32}\\delta h_{22}$$\n",
    "$$\\delta\\omega_{22}=x_{22}\\delta h_{11}+x_{23}\\delta h_{12}+x_{32}\\delta h_{21}+x_{33}\\delta h_{22}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution(object):\n",
    "    \n",
    "    def conv_forward(self, X, W):\n",
    "        '''\n",
    "        The forward computation for a convolution function\n",
    "\n",
    "        Arguments:\n",
    "        X -- output activations of the previous layer, numpy array of shape (n_H_prev, n_W_prev) assuming input channels = 1\n",
    "        W -- Weights, numpy array of size (f, f) assuming number of filters = 1\n",
    "\n",
    "        Returns:\n",
    "        H -- conv output, numpy array of size (n_H, n_W)\n",
    "        cache -- cache of values needed for conv_backward() function\n",
    "        '''\n",
    "\n",
    "        # Retrieving dimensions from X's shape\n",
    "        (n_H_prev, n_W_prev) = X.shape\n",
    "\n",
    "        # Retrieving dimensions from W's shape\n",
    "        (f, f) = W.shape\n",
    "\n",
    "        # Compute the output dimensions assuming no padding and stride = 1\n",
    "        n_H = n_H_prev - f + 1\n",
    "        n_W = n_W_prev - f + 1\n",
    "\n",
    "        # Initialize the output H with zeros\n",
    "        H = np.zeros((n_H, n_W))\n",
    "\n",
    "        # Looping over vertical(h) and horizontal(w) axis of output volume\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                x_slice = X[h:h+f, w:w+f]\n",
    "                H[h,w] = np.sum(x_slice * W)\n",
    "\n",
    "        # Saving information in 'cache' for backprop\n",
    "        cache = (X, W)\n",
    "\n",
    "        return H, cache\n",
    "    \n",
    "    def conv_backward(self, dH, cache):\n",
    "        '''\n",
    "        The backward computation for a convolution function\n",
    "\n",
    "        Arguments:\n",
    "        dH -- gradient of the cost with respect to output of the conv layer (H), numpy array of shape (n_H, n_W) assuming channels = 1\n",
    "        cache -- cache of values needed for the conv_backward(), output of conv_forward()\n",
    "\n",
    "        Returns:\n",
    "        dX -- gradient of the cost with respect to input of the conv layer (X), numpy array of shape (n_H_prev, n_W_prev) assuming channels = 1\n",
    "        dW -- gradient of the cost with respect to the weights of the conv layer (W), numpy array of shape (f,f) assuming single filter\n",
    "        '''\n",
    "\n",
    "        # Retrieving information from the \"cache\"\n",
    "        (X, W) = cache\n",
    "\n",
    "        # Retrieving dimensions from X's shape\n",
    "        (n_H_prev, n_W_prev) = X.shape\n",
    "\n",
    "        # Retrieving dimensions from W's shape\n",
    "        (f, f) = W.shape\n",
    "\n",
    "        # Retrieving dimensions from dH's shape\n",
    "        (n_H, n_W) = dH.shape\n",
    "\n",
    "        # Initializing dX, dW with the correct shapes\n",
    "        dX = np.zeros(X.shape)\n",
    "        dW = np.zeros(W.shape)\n",
    "\n",
    "        # Looping over vertical(h) and horizontal(w) axis of the output\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                dX[h:h+f, w:w+f] += W * dH(h,w)\n",
    "                dW += X[h:h+f, w:w+f] * dH(h,w)\n",
    "\n",
    "        return dX, dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELU ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(object):\n",
    "    def __init__(self, shape):\n",
    "        self.eta = np.zeros(shape)\n",
    "        self.x = np.zeros(shape)\n",
    "        self.output_shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def gradient(self, eta):\n",
    "        self.eta = eta\n",
    "        self.eta[self.x<0]=0\n",
    "        return self.eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling(object):\n",
    "    def __init__(self, shape, ksize=2, stride=2):\n",
    "        self.input_shape = shape\n",
    "        self.ksize = ksize\n",
    "        self.stride = stride\n",
    "        self.output_channels = shape[-1]\n",
    "        self.index = np.zeros(shape)\n",
    "        self.output_shape = [shape[0], shape[1] / self.stride, shape[2] / self.stride, self.output_channels]\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = np.zeros([x.shape[0], x.shape[1] / self.stride, x.shape[2] / self.stride, self.output_channels])\n",
    "\n",
    "        for b in range(x.shape[0]):\n",
    "            for c in range(self.output_channels):\n",
    "                for i in range(0, x.shape[1], self.stride):\n",
    "                    for j in range(0, x.shape[2], self.stride):\n",
    "                        out[b, i / self.stride, j / self.stride, c] = np.max(\n",
    "                            x[b, i:i + self.ksize, j:j + self.ksize, c])\n",
    "                        index = np.argmax(x[b, i:i + self.ksize, j:j + self.ksize, c])\n",
    "                        self.index[b, i+index/self.stride, j + index % self.stride, c] = 1\n",
    "        return out\n",
    "\n",
    "    def gradient(self, eta):\n",
    "        return np.repeat(np.repeat(eta, self.stride, axis=1), self.stride, axis=2) * self.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution and Pooling ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d12aaaa780>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADqJJREFUeJzt3X+sVPWZx/HPIy3+ACQiFxYteinixh+Jl82EbKLZsKk2sDZBohiIEtYQaQioNfVXMKbGaCLrtghxJV4WIsSWtqG48odZq6YRm9TGEUwR2d0avPIz3EuE1Gq0/Hj2j3tobvHOd4aZM3OG+7xfyc3MnOd873ky8LlnZr4z8zV3F4B4zim6AQDFIPxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4L6RisPNnbsWO/s7GzlIYFQenp6dPjwYatl34bCb2YzJK2UNEzSf7r706n9Ozs7VS6XGzkkgIRSqVTzvnU/7DezYZL+Q9JMSVdLmmdmV9f7+wC0ViPP+adJ+sjdd7v7XyT9XNKsfNoC0GyNhP9SSXsH3N6XbfsbZrbIzMpmVu7r62vgcADy1Ej4B3tR4WufD3b3bncvuXupo6OjgcMByFMj4d8naeKA29+SdKCxdgC0SiPhf1fSFDObZGbDJc2VtCWftgA0W91Tfe5+3MyWSnpN/VN969x9Z26dAWiqhub53f1VSa/m1AuAFuLtvUBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1dIlujH07N27N1lfuXJlxdqKFSuSY++///5k/b777kvWJ06cmKxHx5kfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JqaJ7fzHokfSbphKTj7l7Koym0j/379yfrU6dOTdaPHj1asWZmybHPPvtssr5+/fpkva+vL1mPLo83+fyzux/O4fcAaCEe9gNBNRp+l/RrM3vPzBbl0RCA1mj0Yf/17n7AzMZJet3M/sfdtw7cIfujsEiSLrvssgYPByAvDZ353f1Adtkr6WVJ0wbZp9vdS+5e6ujoaORwAHJUd/jNbISZjTp1XdJ3JX2QV2MAmquRh/3jJb2cTdd8Q9LP3P2/c+kKQNPVHX533y3puhx7QQE++eSTZH369OnJ+pEjR5L11Fz+6NGjk2PPPffcZL23tzdZ3717d8Xa5Zdfnhw7bNiwZH0oYKoPCIrwA0ERfiAowg8ERfiBoAg/EBRf3T0EHDt2rGKt2lTejBkzkvVqX83diK6urmT9qaeeStZvuOGGZH3KlCkVa93d3cmxCxcuTNaHAs78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU8/xDwIMPPlix9txzz7WwkzPz1ltvJeuff/55sj579uxkffPmzRVr27dvT46NgDM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFPP9ZoNpn6l966aWKNXdv6NjV5tJvvfXWZP3OO++sWJs4cWJy7FVXXZWsP/zww8n6pk2bKtYavV+GAs78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxCUVZvvNLN1kr4nqdfdr822jZH0C0mdknok3e7u6bWaJZVKJS+Xyw22PPTs378/Wb/uuvRK6EePHq372HfccUeyvmbNmmT9ww8/TNa3bdtWsTZ37tzk2AsuuCBZrya1zPaIESOSY3fu3JmsV3uPQlFKpZLK5XLlddEHqOXM/6Kk01d2eETSm+4+RdKb2W0AZ5Gq4Xf3rZI+PW3zLEnrs+vrJd2Sc18Amqze5/zj3f2gJGWX4/JrCUArNP0FPzNbZGZlMyv39fU1+3AAalRv+A+Z2QRJyi57K+3o7t3uXnL3UkdHR52HA5C3esO/RdKC7PoCSa/k0w6AVqkafjPbKOl3kv7ezPaZ2UJJT0u6ycz+KOmm7DaAs0jVz/O7+7wKpe/k3MuQdfjw4WR9+fLlyfqRI+m3UIwfP75ibdKkScmxixcvTtaHDx+erHd1dTVUL8oXX3yRrD/zzDPJ+qpVq/JspxC8ww8IivADQRF+ICjCDwRF+IGgCD8QFF/dnYPjx48n6w888ECynvrqbUkaPXp0sv7aa69VrF1xxRXJsceOHUvWo/r444+LbqHpOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDM8+dgz549yXq1efxq3nnnnWT9yiuvrPt3n3/++XWPxdmNMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU8fw6WLFmSrFdbBn327NnJeiPz+JGdPHmyYu2cc9LnvWr/ZkMBZ34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrqPL+ZrZP0PUm97n5ttu1xSXdL6st2W+burzaryXawffv2irWtW7cmx5pZsj5nzpy6ekJaai6/2r9JqVTKu522U8uZ/0VJMwbZvsLdu7KfIR18YCiqGn533yrp0xb0AqCFGnnOv9TM/mBm68zsotw6AtAS9YZ/taTJkrokHZT040o7mtkiMyubWbmvr6/SbgBarK7wu/shdz/h7iclrZE0LbFvt7uX3L3U0dFRb58AclZX+M1swoCbsyV9kE87AFqllqm+jZKmSxprZvsk/UjSdDPrkuSSeiR9v4k9AmiCquF393mDbF7bhF7a2pdfflmx9tVXXyXHXnLJJcn6zTffXFdPQ93x48eT9VWrVtX9u2+77bZkfdmyZXX/7rMF7/ADgiL8QFCEHwiK8ANBEX4gKMIPBMVXd7fAeeedl6yPHDmyRZ20l2pTeatXr07WH3rooWS9s7OzYu3RRx9Njh0+fHiyPhRw5geCIvxAUIQfCIrwA0ERfiAowg8ERfiBoJjnb4H58+cX3UJh9u/fX7G2fPny5Njnn38+Wb/rrruS9TVr1iTr0XHmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgmOevkbvXVZOkF198MVl/7LHH6mmpLWzcuDFZv+eeeyrWjhw5khx77733JusrVqxI1pHGmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqo6z29mEyVtkPR3kk5K6nb3lWY2RtIvJHVK6pF0u7unJ27PYmZWV02S9u3bl6w/8cQTyfrChQuT9VGjRlWs7dy5Mzn2hRdeSNbffvvtZL2npydZnzx5csXa3Llzk2OrzfOjMbWc+Y9L+qG7XyXpHyUtMbOrJT0i6U13nyLpzew2gLNE1fC7+0F335Zd/0zSLkmXSpolaX2223pJtzSrSQD5O6Pn/GbWKWmqpN9LGu/uB6X+PxCSxuXdHIDmqTn8ZjZS0q8k/cDd/3QG4xaZWdnMyn19ffX0CKAJagq/mX1T/cH/qbtvzjYfMrMJWX2CpN7Bxrp7t7uX3L3U0dGRR88AclA1/Nb/UvZaSbvc/ScDSlskLciuL5D0Sv7tAWiWWj7Se72k+ZJ2mNn72bZlkp6W9EszWyhpj6Q5zWnx7HfixIlkvdpU39q1a5P1MWPGVKzt2LEjObZRM2fOTNZnzJhRsbZ06dK828EZqBp+d/+tpEoT2d/Jtx0ArcI7/ICgCD8QFOEHgiL8QFCEHwiK8ANB8dXdNbrmmmsq1m688cbk2DfeeKOhY1f7SHBqGexqxo1LfyRj8eLFyfrZ/LXj0XHmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgmOev0YUXXlixtmnTpuTYDRs2JOvN/IrqJ598Mlm/++67k/WLL744z3bQRjjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ5u4tO1ipVPJyudyy4wHRlEollcvl9JrxGc78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU1fCb2UQz+42Z7TKznWZ2X7b9cTPbb2bvZz//0vx2AeSlli/zOC7ph+6+zcxGSXrPzF7Paivc/d+b1x6AZqkafnc/KOlgdv0zM9sl6dJmNwaguc7oOb+ZdUqaKun32aalZvYHM1tnZhdVGLPIzMpmVu7r62uoWQD5qTn8ZjZS0q8k/cDd/yRptaTJkrrU/8jgx4ONc/dudy+5e6mjoyOHlgHkoabwm9k31R/8n7r7Zkly90PufsLdT0paI2la89oEkLdaXu03SWsl7XL3nwzYPmHAbrMlfZB/ewCapZZX+6+XNF/SDjN7P9u2TNI8M+uS5JJ6JH2/KR0CaIpaXu3/raTBPh/8av7tAGgV3uEHBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IqqVLdJtZn6RPBmwaK+lwyxo4M+3aW7v2JdFbvfLs7XJ3r+n78loa/q8d3Kzs7qXCGkho197atS+J3upVVG887AeCIvxAUEWHv7vg46e0a2/t2pdEb/UqpLdCn/MDKE7RZ34ABSkk/GY2w8z+18w+MrNHiuihEjPrMbMd2crD5YJ7WWdmvWb2wYBtY8zsdTP7Y3Y56DJpBfXWFis3J1aWLvS+a7cVr1v+sN/Mhkn6P0k3Sdon6V1J89z9w5Y2UoGZ9UgquXvhc8Jm9k+S/ixpg7tfm237N0mfuvvT2R/Oi9z94Tbp7XFJfy565eZsQZkJA1eWlnSLpH9Vgfddoq/bVcD9VsSZf5qkj9x9t7v/RdLPJc0qoI+25+5bJX162uZZktZn19er/z9Py1XorS24+0F335Zd/0zSqZWlC73vEn0VoojwXypp74Db+9ReS367pF+b2XtmtqjoZgYxPls2/dTy6eMK7ud0VVdubqXTVpZum/uunhWv81ZE+Adb/aedphyud/d/kDRT0pLs4S1qU9PKza0yyMrSbaHeFa/zVkT490maOOD2tyQdKKCPQbn7geyyV9LLar/Vhw+dWiQ1u+wtuJ+/aqeVmwdbWVptcN+104rXRYT/XUlTzGySmQ2XNFfSlgL6+BozG5G9ECMzGyHpu2q/1Ye3SFqQXV8g6ZUCe/kb7bJyc6WVpVXwfdduK14X8iafbCrjWUnDJK1z96da3sQgzOzb6j/bS/2LmP6syN7MbKOk6er/1NchST+S9F+SfinpMkl7JM1x95a/8Faht+nqf+j615WbTz3HbnFvN0h6W9IOSSezzcvU//y6sPsu0dc8FXC/8Q4/ICje4QcERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKj/BxmeJtv9WSKzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d12aa2f588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 1\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.3247758   1.16638819 -0.04997238]\n",
      " [ 0.12906474 -1.64199005  0.28984497]\n",
      " [ 1.04272033 -1.02288782 -1.22527963]]\n"
     ]
    }
   ],
   "source": [
    "CONV_FILTER = np.random.standard_normal((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,  -62.48926096, -246.98673931, -419.45617147,\n",
       "         -287.81754541,   39.90509997,  114.64814206,   52.13601664,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -58.81342208, -325.93307284, -539.82333267, -499.53409577,\n",
       "         -652.58951187, -499.32426911,  -41.23709831,  253.57795568,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,  -66.16509984,\n",
       "         -319.46185876, -498.26539262, -590.88097097, -491.57532541,\n",
       "         -498.89981387, -762.66826463, -593.60210333,  161.45879295,\n",
       "           53.29773207,    6.256322  ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,  -12.25279627,  -83.74565577, -309.75707363,\n",
       "         -500.60544542, -582.53238208, -416.46230441, -587.28099416,\n",
       "         -391.6654528 , -514.5169455 , -904.77271606, -518.81112302,\n",
       "          136.52068019,  127.98626901,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        , -196.82212944, -474.53038234, -431.57677214,\n",
       "         -539.15239428, -435.94895263, -632.8747318 , -678.49123557,\n",
       "         -454.16003917, -163.27071925, -750.4210334 , -881.53546565,\n",
       "         -143.19732101,  181.9315386 ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -62.48926096, -297.03882328, -686.20221564, -594.7802118 ,\n",
       "         -366.81038298, -393.61168865, -589.68666057, -778.70431213,\n",
       "         -482.86115135, -159.67975725, -398.85607012, -771.77852346,\n",
       "         -340.37934825,   35.10817902,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,  -58.81342208,\n",
       "         -325.93307284, -525.07107726, -451.72307451, -460.30422942,\n",
       "         -315.24102966, -216.36278185, -353.13689551, -459.75321707,\n",
       "         -268.12015153, -234.26690831, -279.11057059, -879.98276364,\n",
       "         -429.34174874,    2.68196677,   52.13601664,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,  -46.56062582, -227.12831683,\n",
       "         -451.52987329, -636.19713641, -342.01212179, -434.94868812,\n",
       "         -176.51733214,   -6.52578559, -217.91139606,  -50.23612905,\n",
       "          -90.44543132, -248.46609642, -219.52771981, -728.17589928,\n",
       "         -689.85319448, -179.3100724 ,  178.50209173,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,   -8.57695739, -214.24587937, -500.51533084,\n",
       "         -514.83053473, -194.89821846, -169.25487504, -315.68315904,\n",
       "         -245.57055727, -186.8485314 ,   65.53514678,   40.7253654 ,\n",
       "         -135.80372016,  -27.82029185, -249.30797902, -626.99071075,\n",
       "         -620.42727536, -438.70275627,  158.38735629,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,  -67.81202392, -328.87554729, -689.3556714 ,\n",
       "         -263.97044073,  -77.78607487,  -88.20140656,  -84.18025442,\n",
       "         -221.10025075, -107.66735476,    0.        ,    0.        ,\n",
       "            0.        ,    0.        , -249.30797902, -627.44046214,\n",
       "         -606.98125581, -365.75079874,    9.91008113,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        , -226.43400937, -533.81039925, -432.76836391,\n",
       "         -247.41102794,   69.73742715, -227.95102809,  -73.29693296,\n",
       "            7.48812896,  -37.09372246,    0.        ,    0.        ,\n",
       "            0.        ,    0.        , -251.75853827, -630.7115174 ,\n",
       "         -608.64315388, -330.73932066,  -28.7904726 ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -93.12125163, -324.6173834 , -679.04628862, -267.46340404,\n",
       "         -174.18458249, -119.05406927,  -83.46087554,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        , -248.72828908, -630.43459727,\n",
       "         -551.98630025, -284.1963511 ,  -78.71198384,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -82.12055046, -459.09984198, -553.7286665 , -329.40374549,\n",
       "          -50.67961394, -211.18414362,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           -8.57695739, -172.57296433, -380.19873672, -403.52195786,\n",
       "         -331.89950893, -135.37507977, -228.04183224,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -83.30984631, -385.89185458, -604.86501185, -340.78766436,\n",
       "           17.95374689, -145.14827143,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,   -8.57695739,\n",
       "         -165.64293102, -407.83458688, -556.93671975, -115.96449566,\n",
       "         -155.92595889,  -82.88274671, -194.51804188,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -83.75959769, -375.69419516, -515.14737659, -286.01620672,\n",
       "          -95.56284539,  -33.11939505,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,  -58.81342208, -249.24083882,\n",
       "         -401.37042553, -437.43011492, -110.3069996 ,  -28.99722216,\n",
       "         -206.36147202, -223.24804469,  -15.89730963,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -84.98487732, -377.94236261, -635.40801533, -245.64469549,\n",
       "          -42.09854223,    0.        ,    0.        ,    0.        ,\n",
       "            0.        , -139.68187745, -394.31320367, -465.91383698,\n",
       "         -399.19246066, -113.31183111,   26.52113635,  -52.62599969,\n",
       "         -215.26099431,  -94.05908195,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -83.46975272, -377.04634024, -639.26204117, -672.33596692,\n",
       "         -111.57060611,   67.6054442 ,  -83.76193899, -274.80634834,\n",
       "         -369.13071913, -321.49895841, -418.01833653, -423.92572078,\n",
       "         -228.39070783,  -49.79983813,  -52.7575201 , -229.18621378,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -83.80957007, -374.57777935, -638.62485313, -710.51745198,\n",
       "         -767.34666578, -286.47747282, -306.694172  , -426.58719653,\n",
       "         -519.86128028, -513.99732489, -297.68050127,  -99.77558876,\n",
       "         -121.9418959 , -216.61102387, -207.38605471,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -13.91865897, -252.44976938, -644.0182723 , -717.96190749,\n",
       "         -781.85580667, -724.85013265, -587.17268874, -541.65458679,\n",
       "         -377.68176121, -215.82822357, -114.55362675, -271.57111795,\n",
       "          -86.65821422, -155.91982057,  -74.18744492,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            3.86800722,   67.62139409, -263.77842206, -781.19549445,\n",
       "         -793.57902844, -692.13846539, -540.00433296, -244.01031953,\n",
       "         -251.36184845, -219.14408691,  -93.01343989, -108.02559309,\n",
       "         -172.22085428,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           -1.39922653,   29.96049062,  178.47489267, -116.2007763 ,\n",
       "         -376.48711996, -361.19856711, -394.09146811, -239.829263  ,\n",
       "         -111.87655357, -134.77107974, -192.09249131,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,   -1.2493094 ,   22.76324049,  103.58525391,\n",
       "          111.71550893,  -51.34032998,  -48.28456021, -171.23174589,\n",
       "         -143.63702524,  -49.01670468,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ,    0.        ,    0.        ,\n",
       "            0.        ,    0.        ]]),\n",
       " (array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
       "          224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
       "          252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
       "          253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
       "          179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
       "           84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
       "           28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
       "            0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
       "            0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
       "          178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
       "          252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
       "          233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
       "           37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0]], dtype=uint8),\n",
       "  array([[-1.3247758 ,  1.16638819, -0.04997238],\n",
       "         [ 0.12906474, -1.64199005,  0.28984497],\n",
       "         [ 1.04272033, -1.02288782, -1.22527963]])))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = Convolution()\n",
    "conv2 = Convolution()\n",
    "conv1.conv_forward(x_train[image_index], conv_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_channels = 12\n",
    "ksize = 5\n",
    "stride = 1\n",
    "eta = np.zeros((BATCH_SIZE, int((28 - ksize + 1) / stride), int((28 - ksize + 1) / stride), output_channels))\n",
    "output_shape = eta.shape\n",
    "\n",
    "relu1 = Relu(output_shape)\n",
    "pool1 = MaxPooling(relu1.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "hidden_layer_1 = NeuronLayer(input_num=15, neuron_num=10, bias=1)\n",
    "hidden_layer_2 = NeuronLayer(input_num=10, neuron_num=10, bias=1)\n",
    "output_layer = NeuronLayer(input_num=10, neuron_num=1, bias=1)\n",
    "nn.add_layer(hidden_layer_1)\n",
    "nn.add_layer(hidden_layer_2)\n",
    "nn.add_layer(output_layer)\n",
    "# nn.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-073ec7c5df1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_total_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "tracking = []\n",
    "BATCH_SIZE = 64\n",
    "for i in range(1):\n",
    "    nn.train(dataset, 0)\n",
    "    tracking.append(nn.calculate_total_error(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "img = x_train[i * BATCH_SIZE:(i + 1) * BATCH_SIZE].reshape([BATCH_SIZE, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
